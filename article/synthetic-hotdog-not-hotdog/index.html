<!doctype html>
<html data-n-head-ssr>
  <head>
    <title>John Sutor's Website</title><meta data-n-head="ssr" charset="utf-8"><meta data-n-head="ssr" name="viewport" content="width=device-width,initial-scale=1"><meta data-n-head="ssr" data-hid="description" name="description" content="A collection of jumbled ideas mixed in with some coding."><meta data-n-head="ssr" property="og:site_name" content="John Sutor's Website"><meta data-n-head="ssr" data-hid="og:type" property="og:type" content="website"><meta data-n-head="ssr" data-hid="og:url" property="og:url" content="https://johnsutor.github.io"><meta data-n-head="ssr" data-hid="og:title" property="og:title" content="John Sutor's Website"><meta data-n-head="ssr" data-hid="og:description" property="og:description" content="A collection of jumbled ideas mixed in with some coding."><meta data-n-head="ssr" data-hid="og:image" property="og:image" content="/og.jpg"><meta data-n-head="ssr" property="og:image:width" content="600"><meta data-n-head="ssr" property="og:image:height" content="800"><link data-n-head="ssr" rel="icon" type="image/x-icon" href="/favicon.ico"><link rel="preload" href="/_nuxt/runtime.f9372b3.js" as="script"><link rel="preload" href="/_nuxt/vendors/commons.1fbb7c5.js" as="script"><link rel="preload" href="/_nuxt/app.ba35abe.js" as="script"><link rel="preload" href="/_nuxt/pages/article/_slug.ee7a07d.js" as="script"><style data-vue-ssr-id="517a8dd7:0 fa7ff0ca:0 56b15182:0 0bc75440:0 007e9ba0:0">code[class*=language-],pre[class*=language-]{color:#000;background:0 0;text-shadow:0 1px #fff;font-family:Consolas,Monaco,"Andale Mono","Ubuntu Mono",monospace;font-size:1em;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;word-wrap:normal;line-height:1.5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-hyphens:none;-ms-hyphens:none;hyphens:none}code[class*=language-] ::-moz-selection,code[class*=language-]::-moz-selection,pre[class*=language-] ::-moz-selection,pre[class*=language-]::-moz-selection{text-shadow:none;background:#b3d4fc}code[class*=language-] ::selection,code[class*=language-]::selection,pre[class*=language-] ::selection,pre[class*=language-]::selection{text-shadow:none;background:#b3d4fc}@media print{code[class*=language-],pre[class*=language-]{text-shadow:none}}pre[class*=language-]{padding:1em;margin:.5em 0;overflow:auto}:not(pre)>code[class*=language-],pre[class*=language-]{background:#f5f2f0}:not(pre)>code[class*=language-]{padding:.1em;border-radius:.3em;white-space:normal}.token.cdata,.token.comment,.token.doctype,.token.prolog{color:#708090}.token.punctuation{color:#999}.token.namespace{opacity:.7}.token.boolean,.token.constant,.token.deleted,.token.number,.token.property,.token.symbol,.token.tag{color:#905}.token.attr-name,.token.builtin,.token.char,.token.inserted,.token.selector,.token.string{color:#690}.language-css .token.string,.style .token.string,.token.entity,.token.operator,.token.url{color:#9a6e3a;background:hsla(0,0%,100%,.5)}.token.atrule,.token.attr-value,.token.keyword{color:#07a}.token.class-name,.token.function{color:#dd4a68}.token.important,.token.regex,.token.variable{color:#e90}.token.bold,.token.important{font-weight:700}.token.italic{font-style:italic}.token.entity{cursor:help}.nuxt-progress{position:fixed;top:0;left:0;right:0;height:2px;width:0;opacity:1;transition:width .1s,opacity .4s;background-color:#000;z-index:999999}.nuxt-progress.nuxt-progress-notransition{transition:none}.nuxt-progress-failed{background-color:red}body{max-width:100%;font-family:-apple-system,BlinkMacSystemFont,"Segoe UI",Roboto,Helvetica,Arial,sans-serif,"Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol"}@media only screen and (min-width:768px){nav{font-size:1.5rem}}nav{color:#005397;display:flex;justify-content:space-around;align-items:center;height:4rem;width:100%;border-bottom:2px solid #20ad65}nav .links a{margin-left:1rem}a,a:active,a:focus,a:hover{text-decoration:none;color:inherit}article{color:#005397}@media only screen and (min-width:768px){article{margin-top:4rem;width:50%;display:block;margin-left:auto;margin-right:auto}}@media only screen and (max-width:768px){article{width:80vw;margin-top:2rem;margin-left:auto;margin-right:auto}}.nuxt-content img{width:100%}.nuxt-content a{font-weight:700}</style><link rel="preload" href="/_nuxt/static/1615342222/article/synthetic-hotdog-not-hotdog/payload.js" as="script">
  </head>
  <body>
    <div data-server-rendered="true" id="__nuxt"><!----><div id="__layout"><div><nav><h1><a href="/" class="nuxt-link-active">
            John Sutor
        </a></h1> <span class="links"><a href="/article/papers">
            Papers
        </a> <a href="https://drive.google.com/file/d/1wlco7MWl_t0r6QGgcvW237cADYHdk-iG/view?usp=sharing" target="_blank">
            Resume
        </a></span></nav> <article><h2>ðŸŒ­ (Synthetic) Hotdog or not Hotdog?</h2> <p> Posted December 31, 2020, updated March 9, 2021 </p> <div class="nuxt-content"><p>When a developer decides to go and flex their deep-learning prowess, it seems like they borrow religiously from the ingenious app creation of JÃ¬an-YÃ¡ng. In the famed episode of <em>Silicon Valley</em> S4E4, JÃ¬an-YÃ¡ng reveals that the revolutionary food app that he's been tirelessly working on is in fact extremely underwhelming: it can only differentiate between images of hotdogs and images that aren't hotdogs. Bummer. Fortunately, the concept of <em>SeeFood</em> provides for an excellent idea for a simple deep computer vision project that doesn't involve working with the rather banal hand-written digits of the <a href="http://yann.lecun.com/exdb/mnist/" rel="nofollow noopener noreferrer" target="_blank">MNIST Dataset</a> or the abysmal low-resolution images of <a href="https://www.cs.toronto.edu/~kriz/cifar.html" rel="nofollow noopener noreferrer" target="_blank">CIFAR-10</a>.</p>
<p>In the spirit of reinventing the wheel and copying personal projects of other developers, I decided to create my own hotdog-detecting binary classification algorithm. This time, however, there's a special twist: we'll use synthetic data to aid the production process and generate our own data to increase the accuracy of the algorithm.</p>
<p><img alt="Hotdog" src="/article1/hotdog.jpg" title="The best hotdog to ever exist">
One of the most famous hotdogs | Wired.com</p>
<h2 id="wait-whats-synthetic-data"><a href="#wait-whats-synthetic-data" aria-hidden="true" tabindex="-1"><span class="icon icon-link"></span></a>Wait, What's Synthetic Data?</h2>
<p>Glad you asked. Synthetic data is any data that is generated algorithmically to simulate real data that is hard and/or expensive to collect and label. Synthetic data exists for a variety of niche topics, whether it is <a href="https://bmcmedresmethodol.biomedcentral.com/articles/10.1186/s12874-020-00977-1" rel="nofollow noopener noreferrer" target="_blank">synthetic medical records</a> that allow researchers to mask patients' sensitive data, to <a href="https://github.com/apple/ml-hypersim" rel="nofollow noopener noreferrer" target="_blank">hyperrealistic indoor images</a> that allow researchers to test and train indoor navigational agents virtually. For those of us who favor more impractical use cases of deep learning, we can create synthetic hotdog images to train a binary hotdog classifier!</p>
<p>Funny enough, the hotdog, not hotdog detector is an ideal case for using synthetic data. The most widely-accepted hotdog, not hotdog <a href="https://www.kaggle.com/dansbecker/hot-dog-not-hot-dog" rel="nofollow noopener noreferrer" target="_blank">dataset</a> only has 499 images of hotdogs and 499 images of non-hotdogs. Compare this to a dataset such as <a href="http://image-net.org" rel="nofollow noopener noreferrer" target="_blank">ImageNet</a> with over fourteen million images divided between over 21,000 separate classes, and it becomes clear why synthetic data is such a necessity for niche applications where data is difficult to collect.</p>
<h2 id="how-can-i-create-synthetic-data"><a href="#how-can-i-create-synthetic-data" aria-hidden="true" tabindex="-1"><span class="icon icon-link"></span></a>How Can I Create Synthetic Data?</h2>
<p>Depending on the domain of your real data, there are a few tools available for generating synthetic data. For working with tabular and time-series data, the <a href="https://sdv.dev/" rel="nofollow noopener noreferrer" target="_blank">Synthetic Data Vault</a> is likely the most applicable to forging your synthetic data. Devised by MIT researchers, the Synthetic Data Vault learns the distribution of tabular and time-series data to create synthetic data that is nearly indistinguishable from your authentic data. This is opposed to random data generators such as <a href="https://mockaroo.com/" rel="nofollow noopener noreferrer" target="_blank">Mockaroo</a> that generate data stochastically such that it doesn't capture the distribution of realistic data. </p>
<p>When it comes to generating visual data instead of tabular or time-series data, it's a bit harder and requires more domain expertise. To create truly robust synthetic data, you need a 3D model(s) or a 3D scene(s) of the object(s) on which you plan to train a classifier. Next, you have to incorporate your 3D model(s)/scene(s) into a rendering pipeline to actually generate synthetic images. However, this alone is not enough to generate robust synthetic data, and will ultimately lead to overfitting on a select set of 3D models/scenes. You must also introduce <a href="https://arxiv.org/abs/1703.06907" rel="nofollow noopener noreferrer" target="_blank">domain randomization</a> into your synthetic data production pipeline in order to train a model that doesn't overfit your data. To achieve this, techniques such as random camera placement, Gaussian Blurring, Gaussian Noise, random backgrounds, and random colorization can be applied. The list of domain randomization techniques goes on and on, though the techniques previously mentioned are often some of the most effective for creating a dataset that can train a strong computer vision model. We'll use a subset of these techniques when we go ahead and train our own model.</p>
<p><img alt="Hotdog" src="/article1/sdv.png">
The Synthetic Data Vault production process | Towards Data Science</p>
<h2 id="hotdog-vs-no-hotdog"><a href="#hotdog-vs-no-hotdog" aria-hidden="true" tabindex="-1"><span class="icon icon-link"></span></a>Hotdog vs No Hotdog</h2>
<p>Now for the exciting part of this blog, where we'll go ahead and build our synthetic dataset, as well as our computer vision model. We'll use <a href="https://pytorch.org/" rel="nofollow noopener noreferrer" target="_blank">Pytorch</a> to take care of the deep-learning related work for our pipeline, and we'll use <a href="https://www.blender.org/" rel="nofollow noopener noreferrer" target="_blank">Blender</a> to take care of the rendering aspect of our pipeline. More specifically, I'll be using a simple script that I created for generating synthetic data in Blender that you can find <a href="">here</a>. This tool can import Blender objects (.dae files), apply a random uniform rotation to the object, apply a random background, Gaussian Noise, and Gaussian Blur, and then render the final image. You can find the 3D .dae files <a href="">here</a>, and the background images that I used <a href="">here</a>. Please note that I opted to use .dae files instead of the more common .obj files due to their ease of integration to the Blender rendering environment. </p>
<p>Next, we'll create a simple binary classifier in Pytorch to train on our synthetic data. In my case, I created the binary classifier in Google Colab because my GTX 1650 isn't necessarily purpose-built for training computer vision models, and I'm too broke to rent out a Tesla v100 or P100 Cloud GPU.</p>
<p><img alt="Hotdog" src="/article1/render_00003.png">
An example synthetic hotdog. Notice the granularity caused by Gaussian Noise, as well as the background.</p>
<h3 id="creating-our-data"><a href="#creating-our-data" aria-hidden="true" tabindex="-1"><span class="icon icon-link"></span></a>Creating our Data</h3>
<p>First, we have to create our synthetic data. As mentioned above, we'll go ahead and import our 3D objects as well as our background images. I went ahead and downloaded twenty images to use as backgrounds from Flickr: ten images of tables (you gotta eat somewhere) and ten images of ballparks (when else would a normal person eat hotdogs?). Next, I went ahead and found some 3D hotdogs on <a href="https://sketchfab.com/search?q=tag%3Ahotdog&sort_by=-relevance&type=models" rel="nofollow noopener noreferrer" target="_blank">Sketchfab</a>. One was low-poly and one was just a pig in a blanket, but I'm too cheap to go ahead and purchase the professionally created 3D hotdog models. Once I had these, I made sure to convert my 3D objects into the .dae format, and I went ahead and put them in the proper directory for the Synthblend script. Finally, I went ahead and rendered 5,000 images of hotdogs because why not. Leveraging parallel mapping via the <a href="https://joblib.readthedocs.io/en/latest/generated/joblib.Parallel.html" rel="nofollow noopener noreferrer" target="_blank">Joblib</a> library, I was able to render a hardy 120 images a minute on my Dell XPS 15.</p>
<p>Please note that all 3D objects and images used in making our synthetic dataset have a creative commons license, though I don't plan on creating a startup with my hotdog detecting algorithm anytime soon (that niche has already been taken care of, unfortunately.) You can find the backgrounds and the objects in their respective folders at <a href="">this</a> repository.</p>
<p><img alt="Hotdog" src="/article1/render_00200.png">
An example of a synthetic taco. Who's hungry?</p>
<h3 id="importing-our-data"><a href="#importing-our-data" aria-hidden="true" tabindex="-1"><span class="icon icon-link"></span></a>Importing our Data</h3>
<p>We'll import the necessary Pytorch packages to create our model. We'll need the base <code>torch</code> and <code>torchvision</code> libraries. We also need to load in our data from two separate folders: one containing images of hotdogs, and another containing images of food that isn't a hotdog.</p>
<div class="nuxt-content-highlight"><pre class="line-numbers language-python"><code><span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>optim <span class="token keyword">import</span> Adam
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader<span class="token punctuation">,</span> random_split

<span class="token keyword">from</span> torchvision <span class="token keyword">import</span> datasets<span class="token punctuation">,</span> transforms
</code></pre></div>
<p>We should also set some default global variables for configuring our model, optimizer, and training loop later on. We can go ahead and define these globals as the following</p>
<div class="nuxt-content-highlight"><pre class="line-numbers language-python"><code>BATCH_SIZE <span class="token operator">=</span> <span class="token number">64</span>
BETA_1 <span class="token operator">=</span> <span class="token number">0.9</span>
BETA_2 <span class="token operator">=</span> <span class="token number">0.99</span>
DEVICE <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">"cuda"</span><span class="token punctuation">)</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">"cpu"</span><span class="token punctuation">)</span>
EPOCHS <span class="token operator">=</span> <span class="token number">10</span>
LEARNING_RATE <span class="token operator">=</span> <span class="token number">1e</span><span class="token operator">-</span><span class="token number">4</span>
</code></pre></div>
<p>Next, we'll go ahead and define our data transforms. We won't get fancy with the augmentations, since the domain randomization techniques applied when the synthetic data was created should suffice. We'll simply crop each image to be 128 by 128 pixels, and then normalize each pixel within the range of -1 and 1.</p>
<div class="nuxt-content-highlight"><pre class="line-numbers language-python"><code>transform <span class="token operator">=</span> transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>
    transforms<span class="token punctuation">.</span>Resize<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre></div>
<p>Finally, we'll go ahead and load in our data using the <code>torchvision</code> ImageFolder class. We'll also create a training and testing split to our authentic data to record the performance of our model. We won't use a validation set in our data since we won't be performing any hyperparameter tuning, and we'll stochastically split our authentic data as 80% training and 20% testing. We won't split our synthetic data into separate training and testing sets because we don't want our binary classifier to perform well on synthetic data; we intend for our classifier to perform well on authentic data. We'll also go ahead and download our dataset from <a href="https://www.kaggle.com/dansbecker/hot-dog-not-hot-dog" rel="nofollow noopener noreferrer" target="_blank">Kaggle</a>, though we won't use it just yet. For now, we'll create a directory structure as follows.</p>
<div class="nuxt-content-highlight"><pre class="line-numbers language-text"><code>ðŸ“‚synthetic
    ðŸ“‚hotdog
    ðŸ“‚not_hotdog
</code></pre></div>
<p>Where synthetic is a directory containing the hotdog and not_hotdog subdirectories. These, as the name suggests, contain our synthetic images of hotdogs and not hotdogs. We can finally create our datasets and dataloaders in Pytorch as follows.</p>
<div class="nuxt-content-highlight"><pre class="line-numbers language-python"><code>synthetic <span class="token operator">=</span> datasets<span class="token punctuation">.</span>ImageFolder<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">'./synthetic'</span><span class="token punctuation">,</span> transform<span class="token operator">=</span>transform<span class="token punctuation">)</span>
authentic <span class="token operator">=</span> datasets<span class="token punctuation">.</span>ImageFolder<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">'./authentic'</span><span class="token punctuation">,</span> transform<span class="token operator">=</span>transform<span class="token punctuation">)</span>

authtrain<span class="token punctuation">,</span> authtest <span class="token operator">=</span> random_split<span class="token punctuation">(</span>authentic<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">799</span><span class="token punctuation">,</span> <span class="token number">199</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

synthloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>dataset<span class="token operator">=</span>synthetic<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>BATCH_SIZE<span class="token punctuation">,</span> shuffle <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">,</span> drop_last <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span>
authloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>dataset<span class="token operator">=</span>authtrain<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>BATCH_SIZE<span class="token punctuation">,</span> shuffle <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">,</span> drop_last <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span>
testloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>dataset<span class="token operator">=</span>authtest<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>BATCH_SIZE<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
</code></pre></div>
<h3 id="creating-our-model"><a href="#creating-our-model" aria-hidden="true" tabindex="-1"><span class="icon icon-link"></span></a>Creating our Model</h3>
<p>For all intents and purposes, we'll use a simple network with residual blocks and average pooling. Could we implement a State-of-the-Art model such as <a href="https://arxiv.org/abs/1905.11946" rel="nofollow noopener noreferrer" target="_blank">EfficientNet</a> with State-of-the-Art activation functions such as the <a href="https://arxiv.org/abs/2007.11824" rel="nofollow noopener noreferrer" target="_blank">Funnel Rectified Linear Unit</a>? Of course, we could! Is that way beyond the scope of an article discussing detecting hotdogs? 100%. Instead, we'll implement a super simple Frankenstein <a href="https://arxiv.org/pdf/1512.03385.pdf" rel="nofollow noopener noreferrer" target="_blank">ResNet</a> architecture without downsampling. We can start by creating our own custom residual block that ties together a 1x1 convolution with a 3x3 padded convolution.</p>
<div class="nuxt-content-highlight"><pre class="line-numbers language-python"><code><span class="token keyword">class</span> <span class="token class-name">ResBlock</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_c<span class="token punctuation">,</span> out_c<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>in_c <span class="token operator">=</span> in_c
        self<span class="token punctuation">.</span>out_c <span class="token operator">=</span> out_c 
        self<span class="token punctuation">.</span>relu <span class="token operator">=</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>layers <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>self<span class="token punctuation">.</span>in_c<span class="token punctuation">,</span> self<span class="token punctuation">.</span>out_c<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>self<span class="token punctuation">.</span>out_c<span class="token punctuation">)</span><span class="token punctuation">,</span> 
            self<span class="token punctuation">.</span>relu<span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>self<span class="token punctuation">.</span>out_c<span class="token punctuation">,</span> self<span class="token punctuation">.</span>out_c<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>self<span class="token punctuation">.</span>out_c<span class="token punctuation">)</span>
        <span class="token punctuation">)</span>
        
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        res <span class="token operator">=</span> x
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>layers<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> res <span class="token operator">+</span> x
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
</code></pre></div>
<p>With that, we can go ahead and create our Binary Classifier! Note that we have a linear output layer that outputs a (BATCH_SIZE x 1) tensor, though this should be amended to (BATCH_SIZE x 2) if you plan to use Cross Entropy Loss instead.</p>
<div class="nuxt-content-highlight"><pre class="line-numbers language-python"><code><span class="token keyword">class</span> <span class="token class-name">BinaryClassifier</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>res32 <span class="token operator">=</span> ResBlock<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>res64 <span class="token operator">=</span> ResBlock<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>res128 <span class="token operator">=</span> ResBlock<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>net <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">7</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token comment"># 122</span>
            self<span class="token punctuation">.</span>res32<span class="token punctuation">,</span>
            self<span class="token punctuation">.</span>res32<span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            self<span class="token punctuation">.</span>res64<span class="token punctuation">,</span>
            self<span class="token punctuation">.</span>res64<span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            self<span class="token punctuation">.</span>res128<span class="token punctuation">,</span>
            self<span class="token punctuation">.</span>res128<span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>AvgPool2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>
        <span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>l1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>out <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span>
        
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>net<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> x<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>l1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>out<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> x
</code></pre></div>
<h3 id="creating-the-training-loop"><a href="#creating-the-training-loop" aria-hidden="true" tabindex="-1"><span class="icon icon-link"></span></a>Creating the Training Loop</h3>
<p>Now that we have all the building blocks in place, it's time that we bring it all together and actually train our model. We'll go ahead and use the ADAM optimizer and train our model for thirty epochs total. We'll also allow for three separate training modes: authentic, synthetic or authentic and synthetic (both). This will allow us to test the accuracy of our model when we train it on all three forms of data later on.</p>
<div class="nuxt-content-highlight"><pre class="line-numbers language-python"><code><span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>mode<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">)</span><span class="token punctuation">:</span>  
    <span class="token keyword">if</span> mode <span class="token keyword">not</span> <span class="token keyword">in</span> <span class="token punctuation">[</span><span class="token string">'authentic'</span><span class="token punctuation">,</span> <span class="token string">'synthetic'</span><span class="token punctuation">,</span> <span class="token string">'both'</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
        <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span><span class="token string">"Mode must be one of \'synthetic\', \'authentic\', or \'both\'"</span><span class="token punctuation">)</span>
    optim <span class="token operator">=</span> Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>LEARNING_RATE<span class="token punctuation">,</span> betas<span class="token operator">=</span><span class="token punctuation">(</span>BETA_1<span class="token punctuation">,</span> BETA_2<span class="token punctuation">)</span><span class="token punctuation">)</span>
    criterion <span class="token operator">=</span> nn<span class="token punctuation">.</span>BCELoss<span class="token punctuation">(</span><span class="token punctuation">)</span>
    
    model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
    iters <span class="token operator">=</span> <span class="token number">0</span>
    
    net_loss <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    net_accuracy <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    
    <span class="token keyword">if</span> mode <span class="token operator">==</span> <span class="token string">'synthetic'</span> <span class="token keyword">or</span> mode <span class="token operator">==</span> <span class="token string">'both'</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> E <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>EPOCHS<span class="token punctuation">)</span><span class="token punctuation">:</span>         
            <span class="token keyword">for</span> _<span class="token punctuation">,</span> <span class="token punctuation">(</span>data<span class="token punctuation">,</span> label<span class="token punctuation">)</span> <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>synthloader<span class="token punctuation">)</span><span class="token punctuation">:</span>
                optim<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
                data<span class="token punctuation">,</span> label <span class="token operator">=</span> data<span class="token punctuation">.</span>to<span class="token punctuation">(</span>DEVICE<span class="token punctuation">)</span><span class="token punctuation">,</span> label<span class="token punctuation">.</span>to<span class="token punctuation">(</span>DEVICE<span class="token punctuation">)</span>

                output <span class="token operator">=</span> model<span class="token punctuation">(</span>data<span class="token punctuation">)</span>
                loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>output<span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> label<span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

                loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
                optim<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>

                iters <span class="token operator">+=</span> <span class="token number">1</span>

                <span class="token keyword">if</span> iters <span class="token operator">%</span> <span class="token number">20</span> <span class="token operator">==</span> <span class="token number">19</span><span class="token punctuation">:</span>
                    accuracy <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span><span class="token builtin">round</span><span class="token punctuation">(</span>output<span class="token punctuation">)</span> <span class="token operator">==</span> label<span class="token punctuation">)</span><span class="token operator">/</span>BATCH_SIZE
                    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"iteration: </span><span class="token interpolation"><span class="token punctuation">{</span>iters <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">}</span></span><span class="token string">, loss: </span><span class="token interpolation"><span class="token punctuation">{</span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string">, accuracy: </span><span class="token interpolation"><span class="token punctuation">{</span>accuracy<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>

        torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>model<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string-interpolation"><span class="token string">f'./binary_classifier'</span></span><span class="token punctuation">)</span>    
    
    <span class="token keyword">if</span> mode <span class="token operator">==</span> <span class="token string">'authentic'</span> <span class="token keyword">or</span> mode <span class="token operator">==</span> <span class="token string">'both'</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"\n Fine Tuning \n"</span><span class="token punctuation">)</span>

        <span class="token keyword">for</span> E <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">2</span> <span class="token operator">*</span> EPOCHS <span class="token keyword">if</span> mode <span class="token operator">==</span> <span class="token string">'both'</span> <span class="token keyword">else</span> <span class="token number">3</span> <span class="token operator">*</span> EPOCHS<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>         
            <span class="token keyword">for</span> _<span class="token punctuation">,</span> <span class="token punctuation">(</span>data<span class="token punctuation">,</span> label<span class="token punctuation">)</span> <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>authloader<span class="token punctuation">)</span><span class="token punctuation">:</span>
                model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
                optim<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>

                data<span class="token punctuation">,</span> label <span class="token operator">=</span> data<span class="token punctuation">.</span>to<span class="token punctuation">(</span>DEVICE<span class="token punctuation">)</span><span class="token punctuation">,</span> label<span class="token punctuation">.</span>to<span class="token punctuation">(</span>DEVICE<span class="token punctuation">)</span>

                output <span class="token operator">=</span> model<span class="token punctuation">(</span>data<span class="token punctuation">)</span>
                loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>output<span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> label<span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

                loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
                optim<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>

                iters <span class="token operator">+=</span> <span class="token number">1</span>

                <span class="token keyword">if</span> iters <span class="token operator">%</span> <span class="token number">20</span> <span class="token operator">==</span> <span class="token number">19</span><span class="token punctuation">:</span>
                    <span class="token comment"># Calculate the accuracy wrt the testing set</span>
                    accuracy <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span><span class="token builtin">round</span><span class="token punctuation">(</span>output<span class="token punctuation">)</span> <span class="token operator">==</span> label<span class="token punctuation">)</span><span class="token operator">/</span>BATCH_SIZE
                    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"iteration: </span><span class="token interpolation"><span class="token punctuation">{</span>iters <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">}</span></span><span class="token string">, loss: </span><span class="token interpolation"><span class="token punctuation">{</span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string">, accuracy: </span><span class="token interpolation"><span class="token punctuation">{</span>accuracy<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
        
        torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>model<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string-interpolation"><span class="token string">f"./binary_classifier_</span><span class="token interpolation"><span class="token punctuation">{</span><span class="token string">'finetuned'</span> <span class="token keyword">if</span> mode <span class="token operator">==</span> <span class="token string">'both'</span> <span class="token keyword">else</span> <span class="token string">'authentic'</span><span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
</code></pre></div>
<p>Given that we only use four examples of hotdogs and not hotdogs superimposed onto a set amount of preselected backgrounds, our synthetic data is limited in variance. Therefore, training on authentic data serves two purposes: it avoids overfitting on our synthetic data, and it introduces our model to data from the authentic domain (the data we want to actually able to predict on!) We can go ahead and train first on synthetic and authentic, and then solely on authentic as follows </p>
<div class="nuxt-content-highlight"><pre class="line-numbers language-python"><code>model <span class="token operator">=</span> BinaryClassifier<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>DEVICE<span class="token punctuation">)</span>
train<span class="token punctuation">(</span>mode<span class="token operator">=</span><span class="token string">'authentic'</span><span class="token punctuation">)</span>
train<span class="token punctuation">(</span>mode<span class="token operator">=</span><span class="token string">'synthetic'</span><span class="token punctuation">)</span>
</code></pre></div>
<h2 id="results"><a href="#results" aria-hidden="true" tabindex="-1"><span class="icon icon-link"></span></a>Results</h2>
<p>After training our binary classifier, we can go ahead and test the accuracy of our algorithm. We'll go ahead and create a utility function for calculating the accuracy of our classifier.</p>
<div class="nuxt-content-highlight"><pre class="line-numbers language-python"><code><span class="token keyword">def</span> <span class="token function">calculate_accuracy</span><span class="token punctuation">(</span>model<span class="token punctuation">)</span><span class="token punctuation">:</span>
    model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    
    labels <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    outputs <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> _<span class="token punctuation">,</span> <span class="token punctuation">(</span>data<span class="token punctuation">,</span> label<span class="token punctuation">)</span> <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>testloader<span class="token punctuation">)</span><span class="token punctuation">:</span>
        data <span class="token operator">=</span> data<span class="token punctuation">.</span>to<span class="token punctuation">(</span>DEVICE<span class="token punctuation">)</span>
        output <span class="token operator">=</span> model<span class="token punctuation">(</span>data<span class="token punctuation">)</span>
        
        labels <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>labels<span class="token punctuation">,</span> label<span class="token punctuation">)</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
        outputs <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> output<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
    
    accuracy <span class="token operator">=</span> <span class="token punctuation">(</span>torch<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span><span class="token builtin">round</span><span class="token punctuation">(</span>outputs<span class="token punctuation">)</span> <span class="token operator">==</span> labels<span class="token punctuation">)</span><span class="token operator">/</span><span class="token builtin">len</span><span class="token punctuation">(</span>labels<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Model accuracy: </span><span class="token interpolation"><span class="token punctuation">{</span>accuracy<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
        
    <span class="token keyword">return</span> accuracy 
</code></pre></div>
<p>We can go ahead and run this code using the state dictionaries that we saved for our three separately trained models. The code below will test the accuracy of our model trained solely on authentic data, though you can change the file name to './binary_classifier' and './binary_classifier_both' to determine the model's accuracy on synthetic and synthetic and authentic data, respectively. </p>
<div class="nuxt-content-highlight"><pre class="line-numbers language-python"><code>model <span class="token operator">=</span> BinaryClassifier<span class="token punctuation">(</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">'./binary_classifier_authentic'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>to<span class="token punctuation">(</span>DEVICE<span class="token punctuation">)</span>
acc <span class="token operator">=</span> calculate_accuracy<span class="token punctuation">(</span>model<span class="token punctuation">)</span>
</code></pre></div>
<p>After examining our code, we see that our classifier trained solely on synthetic data achieves a dismal 53.77% accuracy on the testing set. This is pretty disappointing for a binary classifier, given that there's a 50% chance of correctly classifying an image stochastically. However, this is where I must emphasize that <em>synthetic data is not intended to be the sole source of data for training a computer vision model.</em> Instead, synthetic data is intended to be used in tandem with authentic data so that the computer vision can fine-tune itself. If we instead load in our model's fine-tuned state dictionary, we can see that we achieve a fine 83.92% accuracy on the testing set. This is a pretty nice score given that we didn't implement any hyperparameter searching, minimal data augmentation, and are using a shallow Frankenstein ResNet. When we test our model trained on solely authentic data for three epochs, we find that it achieves an accuracy score of 75.37%. Needless to say, incorporating synthetic data into a production pipeline is a steadfast way to gain a significant performance boost on any algorithm.</p>
<p>If you don't feel as if training for ~60 epochs is enough for either classifier, I urge you to go ahead and modify and the code yourself <a href="">here</a> to witness the benefits of synthetic data yourself. If you're still not convinced, may I remind you that we superimposed 3D models of hotdogs onto arbitrarily selected background images pulled from SketchFab and Flickr, respectively?</p>
<p><img alt="Hotdog" src="/article1/138969.jpg">
An example of an authentic hotdog in our dataset.</p>
<h2 id="conclusion"><a href="#conclusion" aria-hidden="true" tabindex="-1"><span class="icon icon-link"></span></a>Conclusion</h2>
<p>Needless to say, synthetic data provides a relatively simple way to increase the accuracy of any computer vision model, especially for domains where collecting data are expensive and/or time-consuming. </p>
<p>That's not to say that synthetic data is the be-all-end-all for training computer vision models. Creating hyperrealistic renders currently requires a ton of manual tweaking on behalf of a researcher, and generating a single batch of images could take upwards of hours to complete. Furthermore, when 3D objects are superimposed on an image backgorund, any person can immediately pick up the discrepancies present in an image. The lighting on the 3D object may disagree with the lighting of the background image. The object may be way out of proportion to the background (as we saw with the 3D hotdogs superimposed onto backgrounds of tables).</p>
<p>There's still a lot of work to be done in this nascent field, though the initial findings prove promising. With recent advances in graphics rendering, it's not hard to imagine that synthetic data can become a necessity for complex computer vision tasks in the near future. If you hae any questions, feel free to <a href="mailto:john@sciteens.org">contact me</a>.</p></div></article></div></div></div><script>window.__NUXT__={staticAssetsBase:"/_nuxt/static/1615342222",layout:"default",error:null,serverRendered:!0,routePath:"/article/synthetic-hotdog-not-hotdog",config:{}}</script><script src="/_nuxt/runtime.f9372b3.js" defer></script><script src="/_nuxt/pages/article/_slug.ee7a07d.js" defer></script><script src="/_nuxt/vendors/commons.1fbb7c5.js" defer></script><script src="/_nuxt/app.ba35abe.js" defer></script>
  </body>
</html>
